package HomeCo::AWS::BackupImageCacher;

use strict;
use base qw{ Exporter };
our @EXPORT = qw{ backup check_parameters };
use File::Find;

# tar sizes from http://www.gnu.org/software/tar/manual/html_node/Standard.html#SEC184
my $tar_record_size = 512; # standard metadata size and data block size for padding
my $tar_blocking_factor = 20; # block to round up output file
my $tar_block_size = $tar_block_size * $tar_round_blocks; # size in bytes of output file round up

sub backup () {
	$config = $_;

	# try to control parameters are checked. Can be circunvent, thou...
	check_parameters( $config ) unless defined $config->{_checked};

	eval {
		if ( $config->{Daily} ) {
			HomeCo::AWS::BackupImageCacher::_backup_daily( $config );
		} elsif ( $config->{Monthly} ) {
			HomeCo::AWS::BackupImageCacher::_backup_monthly( $config );
		}
	};
	if ( $@ ) {
		die( $@ );
	}
}

sub _backup_daily () {

}

sub _backup_monthly () {

}

sub _tar_size_directory () {
	# file path are somehow limited. If path are to long additional info blocks might be generated by tar, since we are streaming we could get into trouble with maximum file pieces

	my $dir = $_;

	die( "Directory does not exist" unless -d $dir );

	my $size_sum = 0; # adds metadata blocks and archive content size with proper rounding

	# -s returns 0 for directories, which is consistent

	File::Find::find( { $size_sum += _tar_archive_member_size( -s $_) }, $dir );



	return $size_sum;
}

sub _tar_archive_member_size() {
	# separate and testable
	my $size = $_;

	# Physically, an archive consists of a series of file entries terminated by an end-of-archive entry,
	# which consists of two 512 blocks of zero bytes. A file entry usually describes one of the files
	# in the archive (an archive member), and consists of a file header and the contents of the file.
	# File headers contain file names and statistics, checksum information which tar uses to detect file
	# corruption, and information about file types.

	# archive member (512) + end-of-archive ( 2 * 512 ) + file contents rounded up to next 512 boundry.
	return 3 * $tar_block_size + ceil( $file_size / $tar_block_size ) * $tar_block_size;
}

sub _tar_output_file_size() {
	# separate and testable
	my $size = $_;

	# from http://www.gnu.org/software/tar/manual/html_node/Standard.html#SEC184
	# A tar archive file contains a series of blocks. Each block contains BLOCKSIZE bytes.

	# round up to next tar block size
	$size = ceil( $size / $tar_block_size ) * $tar_block_size;

	# check minimum size of output file is met or pad
	$size = $tar_block_size if ( $size < $ tar_block_size);

	return $size;
}

sub check_parameters () {
	my $config = $_;

	die("No BaseThumbs defined.") unless defined $config->{BaseThumbs};
	die("BaseThumbs does not exist.") unless -d $config->{BaseThumbs};
	die("No BaseImageCache defined.") unless defined  $config->{BaseImageCache};
	die("BaseImageCache does not exist.") unless -d $config->{BaseImageCache};
	die("VaultRegion does not exist. Set an AWS Region.") unless -d $config->{VaultRegion};
	die("VaultName does not exist. Set an existing AWS Glacier Vault.") unless -d $config->{VaultRegion};
	die("AWSCredentials file does not exist. Provide valid AWS Credetials-") unless -e $config->{AWSCredentials};

	# check date is valid
	die("Provided date is invalid " . $config->{Date} . ".") unless eval {
		my ($year, $month, $day) = unpack "A4 A2 A2", $config->{Date},;
		timelocal(0,0,0,$day, $month-1, $year);
		1;
	}

	# either daily or monthly
	die("Cannot request daily and monthly backup in a single run.") if ( $config->{Daily} && $config->{Monthly} );
	die("Either daily or monthly must be specified.") if ( !$config->{Daily} && !$config->{Monthly} );

	$config->{_checked} = 1;
}
